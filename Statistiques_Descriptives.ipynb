{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b21ac95f",
   "metadata": {},
   "source": [
    "---\n",
    "Introduction à Python et Statistiques Descriptives\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7734812b",
   "metadata": {},
   "source": [
    "Ce premier TP vise à s'approprier les commandes de bases en Python, et à apprendre les premières étapes d'importation, de représentation et de traitement de données.\n",
    "\n",
    "Les données utilisées sont issues de [éCO2mix](https://www.rte-france.com/eco2mix), le site de l'entreprise RTE (le gestionnaire du Réseau de Transport d’Electricité français) qui répertorie les données de l'électricité en France. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450791d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "Les notions abordées sont les suivantes :\n",
    "\n",
    "1. [Des outils pour coder en Python et rédiger des comptes rendus propres](#section_1)\n",
    "2. [Importer des données, nettoyer des données, simuler des jeux de données](#section_2)\n",
    "3. [Afficher des données (nuages de points, courbes, diagrammes en bâtons, histogrammes, estimation de densité avec l'estimateur à noyau de Nadaraya Watson)](#section_3)\n",
    "4. [Réduction de dimension des données (ACP) et représentation.](#section_4)\n",
    "5. [Statistiques bivariées](#section_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3176776b-a55c-4f87-a193-a6b7db0d5766",
   "metadata": {},
   "source": [
    "Les bibliothèques standard de Python que nous allons utiliser dans ce TP sont numpy, matplotlib et pandas.\n",
    "\n",
    "- Documentation [Pandas](https://pandas.pydata.org/docs/), [Numpy](https://numpy.org/doc/stable/), [Matplotlib](https://matplotlib.org/stable/index.html), [Pyplot](https://matplotlib.org/stable/tutorials/introductory/pyplot.html).\n",
    "- Antisèche [Pandas](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf), [Numpy](https://images.datacamp.com/image/upload/v1676302459/Marketing/Blog/Numpy_Cheat_Sheet.pdf), [Matplotlib](https://matplotlib.org/cheatsheets/)\n",
    "\n",
    "Nous commençons par importer ces bibliothèques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ed8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fced140",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>\n",
    "\n",
    "## 1) Des outils pour coder en Python et rédiger des comptes rendus propres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb6e51",
   "metadata": {},
   "source": [
    "**Jupyter et Anaconda**\n",
    "\n",
    "Les notebook [Jupyter](<https://docs.jupyter.org/en/latest/>) permettent de coder dans les langages : Julia, Python ou R (JuPytR), et de rédiger des comptes rendus en html ou pdf etc. L'extension de ces fichiers est .ipynb.\n",
    "\n",
    "Dans ce cours, on téléchargera [Anaconda](<https://www.anaconda.com/>) puis utilisera JupyterLab à partir de Anaconda, cf. [Page Maxime Sangnier](https://perso.lpsm.paris/~msangnier/pythonM2.html).\n",
    "\n",
    "**Quarto**\n",
    "\n",
    "Plus récent, [Quarto](<https://quarto.org/>) permet de créer des documents (HTML, PDF, MS Word, Markdown), des présentations (PowerPoint, Beamer), des livres ou des sites internet, mais aussi des comptes rendus avec le code intégré.\n",
    "Avec Quarto, on peut intégrer du code en Python, R, Julia...\n",
    "Il est conseillé d'utiliser un éditeur. Par exemple : JupyterLab (.ipynb), RStudio IDE (maintenant [Posit](<https://posit.co/>), pour R), [VS Code](<https://code.visualstudio.com/>) (pour les trois langages, exécute un document .ipynb (Notebook Jupyter, auparavant Notebook IPython) ou .qmd (Quarto Markdown))... Pour Quarto : [Bases de Markdown](<https://quarto.org/docs/authoring/markdown-basics.html>), [Options de Jupyter Notebooks](<https://quarto.org/docs/reference/formats/ipynb.html#citation>).\n",
    "\n",
    "On peut aussi prévisualiser un fichier .ipynb avec quarto, ou le transformer en un fichier .html.\n",
    "\n",
    "Exemple :\n",
    "Si vous le souhaitez, après avoir installé quarto, écrire dans un terminal :\n",
    "- `quarto preview TP1_Introduction_Python_Statistiques_Descriptives.ipynb`\n",
    "- `quarto convert TP1_Introduction_Python_Statistiques_Descriptives.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21085aa6",
   "metadata": {},
   "source": [
    "> **Exercice 1 :**\n",
    "Créer un document `loi_normale.ipynb` qui donne la même sortie que le document `loi_normale.qmd`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c786e",
   "metadata": {},
   "source": [
    "<a id='section_2'></a>\n",
    "\n",
    "## 2) Importer des données, nettoyer des données, simuler des jeux de données\n",
    "\n",
    "De nombreux jeux de données sont disponibles librement : http://www.data.gouv.fr/, https://data.sncf.com/, https://archive.ics.uci.edu/, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4696292-174c-4941-8fab-8e4602115c54",
   "metadata": {},
   "source": [
    "### 2-1) Importer les données "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc7ba4-a8e7-403f-8670-905b7bb0f0a8",
   "metadata": {},
   "source": [
    "> **Exercice 2 :** Importer les données `Annuel définitif 2019` sur la page https://www.rte-france.com/eco2mix/telecharger-les-indicateurs, à l'aide de la fonction `read_csv` de la bibliothèque `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b975b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "puissance_2019 = pd.read_csv(#ToDo, sep=#ToDo,encoding='latin-1',index_col=#ToDo, skipfooter=#ToDo, engine = \"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cbe78e-340b-48c4-be55-92e103fb636d",
   "metadata": {},
   "source": [
    "> **Exercice 3 :** Afficher les premières informations sur les données à l'aide des méthodes `info()` et `describe()` du DataFrame `puissance_2019`, puis lancer les commandes suivantes, observer les sorties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c0622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444c933-8b51-445d-b420-ce8843af5ce1",
   "metadata": {},
   "source": [
    "On peut ensuite extraires des parties des données ou des informations avec les commandes ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "puissance_2019.index\n",
    "puissance_2019.columns\n",
    "puissance_2019.head(n = 4)\n",
    "puissance_2019.tail(n = 4)\n",
    "puissance_2019.values\n",
    "puissance_2019[['Ech. physiques', 'Taux de Co2']]\n",
    "puissance_2019.iloc[range(2),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec97a9b-eae4-49f7-b796-8ba0446dc36a",
   "metadata": {},
   "source": [
    "### 2-2) Nettoyer les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd118cd-0518-438b-b036-41cd30282e94",
   "metadata": {},
   "source": [
    "On peut gérer les données manquantes à l'aide des fonctions suivantes :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c9385",
   "metadata": {},
   "source": [
    "- Retirer les lignes avec des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44eb49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "puissance_2019.copy().dropna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aff2014",
   "metadata": {},
   "source": [
    "- Remplacer les données manquantes à partir de celles de la ligne précédente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3afbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "puissance_2019.copy().fillna(method='ffill').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c32168",
   "metadata": {},
   "source": [
    "- Remplacer les données manquantes à partir de celles de la ligne suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128fd130",
   "metadata": {},
   "outputs": [],
   "source": [
    "puissance_2019.copy().fillna(method='bfill').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc153d5",
   "metadata": {},
   "source": [
    "- Vérifier s'il y a des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268881ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "puissance_2019.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d40e71-3240-4298-8724-093f9c6622c5",
   "metadata": {},
   "source": [
    "On voit que les variables Périmètre, Nature, Date, Heures, Prévision J-1 et Prévision J n'ont jamais de données manquantes. Ce n'est pas le cas des autres variables (sauf Stockage batterie et Déstockage batterie, mais elles ont la même valeur ND). En réalité, une ligne sur deux possède des données manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe12a5a-9887-4c8c-94e1-e80adc5b2bbd",
   "metadata": {},
   "source": [
    "> **Exercice 4 :** Créer un DataFrame `puiss_2019` à partir du DataFrame `puissance_2019` en extrayant seulement les lignes d'indice pair.\n",
    "\n",
    "*On pourra utiliser la fonction `np.arange`, et la méthode `.iloc[]` des DataFrame*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ee7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "puiss_2019 = #ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c8cca-5c46-4cc6-9575-7b7c03429983",
   "metadata": {},
   "source": [
    "> **Exercice 5 :**  Comparer la somme par ligne des colonnes `'Ech. comm. Angleterre'`, `'Ech. comm. Espagne'`, `'Ech. comm. Italie'`, `'Ech. comm. Suisse'`, `'Ech. comm. Allemagne-Belgique'` à la colonne `'Ech. physiques'` de `puiss_2019`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafd8516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbaa1fc-7f5d-4e77-b30f-eb3884659ad8",
   "metadata": {},
   "source": [
    "> **Exercice 6:** Créer un DataFrame `moyen_production` à partir du DataFrame `puiss_2019` en extrayant seulement les colonnes correspondant aux productions de  Fioul, Charbon, Gaz, Nucléaire, Éolien, Solaire, Hydraulique, Bioénergies. La colonne Hydraulique sera la somme de la colonne Hydraulique et de la colonne Pompage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "moyen_production = puiss_2019[['Fioul', #ToDo]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f730fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "moyen_production = moyen_production.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a695acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "moyen_production['Hydraulique'] = puiss_2019.loc[:,['Hydraulique','Pompage']].sum(axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87634bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "moyen_production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c807c8f6-46d7-43db-9005-4384a214f948",
   "metadata": {},
   "source": [
    "> **Exercice 7:**  Construire la colonne `import-export` de valeur nominale \"import\" ou \"export\", qui indique si la France a importé ou exporté de l'électricité de l'Espagne. Ajouter au DataFrame `puiss_2019` la colonne `import-export` avec la valeur `import` si la France a importé plus d'électricité qu'elle n'en a exporté et `export`sinon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_export = pd.DataFrame(#ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833480fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "puiss_2019 = pd.concat(#ToDo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b515f-61e9-4b28-9486-c7ceed03c0b1",
   "metadata": {},
   "source": [
    "> **Exercice 9:**  Construire la colonne `consommation_mille_TWh` d'entiers, qui indiquent la consommation en milliers de Térawatt-heure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "consommation_mille_TWh = pd.DataFrame(data = #ToDo, columns = #ToDo, index = #ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "puiss_2019 = pd.concat([puiss_2019,consommation_mille_TWh],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3daf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "puiss_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacdee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conso_effectif = pd.crosstab(index=#ToDo, columns='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c21cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conso_freq = conso_effectif/conso_effectif.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc63f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "conso_effectif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f4bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conso_freq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da79ba6-90f9-460e-aeb4-e052471b4683",
   "metadata": {},
   "source": [
    "### 2-3) Simuler des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f3a59a-d7da-4ed7-b7d3-2158fb34fee6",
   "metadata": {},
   "source": [
    "Il est possible de générer des données de lois connues en utilisant par exemple les fonctions de `numpy.random`. Pour connaître les fonctions de `numpy.random` (on rappelle que `numpy` a été importée sous le nom ̀`np`), on utilise la fonction `dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a2cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(np.random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be736fc-280a-4134-8eef-14d54a53ac80",
   "metadata": {},
   "source": [
    "> **Exercice 8 :** Générer 4 $n$-échantillons de variables aléatoires des lois suivantes (avec $n = 2000$)\n",
    ">- La loi normale de même moyenne et écart-type que la variable `Consommation`de `puiss_2019`.\n",
    ">- La loi uniforme sur l'intervalle $[\\min(Conso),\\max(Conso)]$ de la variable `Consommation`de `puiss_2019`.\n",
    ">- La loi uniforme sur l'intervalle d'entiers $[\\min(Conso\\_1000),\\max(Conso\\_1000)]$ de la variable `consommation_mille_TWh`de `puiss_2019`.\n",
    ">- La loi binomiale $\\mathcal{B}(N,0.5)$, avec $N$ choisi de sorte que l'espérance de la loi soit aussi proche que possible de la moyenne de la variable `consommation_mille_TWh`de `puiss_2019`. Renormaliser ces données pour qu'elles soient de même variance que la variable `consommation_mille_TWh`de `puiss_2019`, sans que cela n'affecte la moyenne.\n",
    "\n",
    "*On utilisera les fonctions `np.std` et `np.mean` pour calculer l'écart-type et la moyenne d'un échantillon.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rdm\n",
    "\n",
    "n = 2000\n",
    "\n",
    "# Échantillon 1:\n",
    "moyenne = np.mean(puiss_2019[['Consommation']],axis = 0)[0]\n",
    "ecart_type = np.std(puiss_2019[['Consommation']])[0]\n",
    "\n",
    "ech_1 = [#ToDo for x in rdm.randn(n)]\n",
    "\n",
    "# Échantillon 2:\n",
    "min_conso = #ToDo\n",
    "max_conso = #ToDo\n",
    "\n",
    "ech_2 = [#ToDo for x in rdm.rand(n)]\n",
    "\n",
    "# Échantillon 3:\n",
    "min_conso_1000 = #ToDo\n",
    "max_conso_1000 = #ToDo\n",
    "\n",
    "ech_3 = rdm.randint(#ToDo)\n",
    "\n",
    "# Échantillon 4:\n",
    "moyenne_1000 = #ToDo\n",
    "ecart_type_1000 = #ToDo\n",
    "N = np.floor(2*moyenne_1000)\n",
    "p = 0.5\n",
    "\n",
    "ech_aux = rdm.binomial(N,p,n)\n",
    "\n",
    "ecart_type_aux = #ToDo\n",
    "moyenne_aux = #ToDo\n",
    "\n",
    "ech_4 = [#ToDo for x in ech_aux]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4bcab6-4b45-441f-bc7d-c6ed750b478c",
   "metadata": {},
   "source": [
    "<a id='section_3'></a>\n",
    "\n",
    "## 3) Afficher des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4a92a-ad77-46e4-aa66-369d27568e13",
   "metadata": {},
   "source": [
    "### 3-1) Données simulées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f697ce6-fca3-4a72-9e9b-9c4f484dcd52",
   "metadata": {},
   "source": [
    "> **Exercice 9 :** Afin de vérifier la justesse de la méthode de simulation précédente, pour les quatre méthodes, comparer l'histogramme ou diagramme en bâtons des observations à la densité ou au diagramme de la vraie loi ayant servi à générer les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbcbe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm, binom\n",
    "\n",
    "# Échantillon 1:\n",
    "\n",
    "x_1 = np.sort(ech_1)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "(hist_plt, bins_plt, patches) = ax.hist(ech_1, bins=\"auto\", density=True, label = \"Échantillon simulé\")\n",
    "ax.plot(x_1,norm.pdf(x_1, loc = moyenne, scale = ecart_type), color=\"red\", alpha = 0.6, linewidth=2, label=r\"Densité de la loi $\\mathcal{N}(0,1)$\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Échantillon 2:\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "(hist_plt, bins_plt, patches) = #ToDo\n",
    "ax.plot(#ToDo)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Échantillon 3:\n",
    "\n",
    "A = pd.Series(ech_3).value_counts() # On peut aussi utiliser np.bincount(ech_3) \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "markerline, stemline, baseline, = ax.stem(np.arange(min_conso_1000,max_conso_1000+1),1/(max_conso_1000 + 1 - min_conso_1000)*np.ones(max_conso_1000+1 - min_conso_1000), label = \"Vraie loi\")\n",
    "plt.setp(stemline, linewidth = 1.25, color = 'r')\n",
    "plt.setp(markerline, markersize = 4, color = 'r')\n",
    "\n",
    "markerline, stemline, baseline, = ax.stem(A.index,A.values/(A.values.sum()), label = \"Échantillon simulé\", use_line_collection=True)\n",
    "plt.setp(stemline, linewidth = 1.25, color = 'b')\n",
    "plt.setp(markerline, markersize = 4, color = 'b')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Échantillon 4:\n",
    "\n",
    "rv = binom(N, p)\n",
    "\n",
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ed204-b281-4235-97e2-197446264eb9",
   "metadata": {},
   "source": [
    "### 3-1) Données réelles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de97bb9-58ee-40f0-b8fc-3079dc678502",
   "metadata": {},
   "source": [
    "> **Exercice 10:** Après avoir calculé les fréquences pour les différents moyens de production sur l'année 2019 :\n",
    "> - Représenter ces fréquences sur un diagramme en barres.\n",
    "> - Représenter les productions totales par an pour les différents moyens de production sur un diagramme en barres.\n",
    "> - Représenter ces informations à l'aide d'un diagramme circulaire.\n",
    ">\n",
    "> Quel diagramme est-il préférable d'utiliser ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fabc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcule le tableau des fréquences pour les différents moyens de production, sur toute l'année 2019\n",
    "\n",
    "moyen_prod_freq = pd.DataFrame({'moyen' :  ['Fioul', 'Charbon', 'Gaz', 'Nucléaire',\n",
    "       'Eolien', 'Solaire', 'Hydraulique', 'Bioénergies'], 'fréquence' : #ToDo})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22285be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(x = #ToDo,y = #ToDo,data = #ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fafdb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "moyen_prod_total = pd.DataFrame({'moyen' :  ['Fioul', 'Charbon', 'Gaz', 'Nucléaire',\n",
    "       'Eolien', 'Solaire', 'Hydraulique', 'Bioénergies'], 'production totale (MWh)' : #ToDo})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.barplot(#ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31400e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "explode = 0.1*np.ones(8)\n",
    "ax.pie(#ToDo, explode=explode, labels=#ToDo, autopct='%1.1f%%', shadow=False, startangle=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf300e-badc-45c1-b070-f21728fdb980",
   "metadata": {},
   "source": [
    "Quel diagramme est-t-il préférable d'utiliser ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d10313",
   "metadata": {},
   "source": [
    "> **Exercice 11:** Représenter l'histogramme associé à la variable `Consommation` de `puiss_2019`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2326ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.hist(#ToDo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006916b1",
   "metadata": {},
   "source": [
    "> **Exercice 12:** Afficher les observations de la variable `consommation_mille_TWh` à l'aide d'un diagramme en bâtons.\n",
    ">\n",
    "> Tracer le diagramme d'effectifs cumulés (ou fonction de répartition) pour les consommations en milliers de MWh\n",
    ">\n",
    "> Retrouver la valeur de la médiane et des 1er et 3ème quartiles (quantiles d'ordre 25%, 50%, 75%).\n",
    ">\n",
    "> Représenter la courbe représentant les quantiles. Il s'agit de l'inverse du diagramme d'effectifs cumulés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36825cdc",
   "metadata": {},
   "source": [
    "> **Exercice 13:** Représenter le facteur d'émission de CO2 au cours du temps : variable\n",
    "    `Taux de Co2` en fonction de l'heure, la première journée.\n",
    "> \n",
    "> Effectuer une régression linéaire. On pourra utiliser la fonction `LinearRegression` de `sklearn.linear_model`.\n",
    "> Est-ce adapté ici ?\n",
    ">\n",
    "> Même question en considérant l'ensemble des journées de l'année 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4355f039",
   "metadata": {},
   "source": [
    "<a id='section_4'></a>\n",
    "\n",
    "## 4) Réduction de dimension des Données par l'Analyse en Composantes Principales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9e55c-8332-44fa-8403-2726d84085fc",
   "metadata": {},
   "source": [
    "> **Exercice 14:**\n",
    ">- Extraire les données associées aux colonnes `Fioul`à `Énergie` et les lignes correspondantes à la première journée pour le DataFrame `puiss_2019`. On appellera ce nouveau DataFrame `jour_1`.\n",
    ">- Renormaliser les données en faisant en sorte que les colonnes soient toutes de moyenne 0 et de variance 1, on note `jour_1_std` le nouveau DataFrame.\n",
    ">- À l'aide d'une Analyse en composantes principales, pour les lignes correspondant à la première journée, réduire la dimension des données à 2 et les afficher. On donnera une couleur aux points en fonction de l'heure de la journée, selon un dégradé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "jour_1 = puiss_2019.loc[puiss_2019['Date'] == '2019-01-01'][['Fioul', 'Charbon', 'Gaz', 'Nucléaire', 'Eolien', 'Solaire', 'Hydraulique', 'Bioénergies']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a0baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jour_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jour_1_std = #ToDo\n",
    "print(jour_1_std.mean(), jour_1_std.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbcc237",
   "metadata": {},
   "outputs": [],
   "source": [
    "jour_1_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313d74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=#ToDo)\n",
    "print(pca)\n",
    "\n",
    "pca.fit(#ToDo)   # ajuste l'ACP sur les données jour_1_std\n",
    "DataExtract = pca.transform(#ToDo) # transforme (projette) les données sur les axes retenus\n",
    "\n",
    "ACP0 = DataExtract[:,0]\n",
    "ACP1 = DataExtract[:,1]\n",
    "\n",
    "acp = pd.DataFrame({\"ACP0\" : ACP0, \"ACP1\" : ACP1, \"Heure\" : 24*np.arange(np.shape(jour_1_std)[0])/np.shape(jour_1_std)[0]})\n",
    "sns.scatterplot(data=acp, x=\"ACP0\", y=\"ACP1\", hue=\"Heure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b56c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(x = acp['ACP0'],y = acp['ACP1'])\n",
    "variables = jour_1_std.columns\n",
    "pca_variables = pca.transform(np.eye(8))\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    fig.add_annotation(\n",
    "        ax=0, ay=0,\n",
    "        axref=\"x\", ayref=\"y\",\n",
    "        x=pca_variables[i, 0],\n",
    "        y=pca_variables[i, 1],\n",
    "        showarrow=True,\n",
    "        arrowsize=2,\n",
    "        arrowhead=2,\n",
    "        xanchor=\"right\",\n",
    "        yanchor=\"top\"\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=pca_variables[i, 0],\n",
    "        y=pca_variables[i, 1],\n",
    "        ax=0, ay=0,\n",
    "        xanchor=\"center\",\n",
    "        yanchor=\"bottom\",\n",
    "        text=variable,\n",
    "        yshift=5,\n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86ff2d8",
   "metadata": {},
   "source": [
    "<a id='section_5'></a>\n",
    "\n",
    "## 5) Statistiques bivariées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474dd766",
   "metadata": {},
   "source": [
    "On remarque qu'afficher les données en fonction de leurs coordonnées selon des deux premiers axes principaux de l'ACP permet de mettre en avant 3 groupes distincts correspondants à 3 périodes distinctes de la journée : matin, mileu de journée, soir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19722a",
   "metadata": {},
   "source": [
    "> **Exercice 15:** Tracer le boxplot associé aux données de `jour_1_std` et commenter.\n",
    ">\n",
    "> Calculer la variance inter, la variance intra, le rapport de corrélation. Conclure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291ee34f",
   "metadata": {},
   "source": [
    "> **Exercice 16:** Tracer les points selon les variables `Solaire` et `Charbon`. Ces deux variables vous semblent-elles corrélées (positivement ou négativement) ? Le vérifier en affichant la corrélation entre les deux variables.\n",
    "\n",
    "> Même question avec les variables ̀`Solaire` et `Nucléaire` ; `Gaz` et `Eolien`; `Charbon` et `Gaz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae87fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(#ToDo)\n",
    "fig.show()\n",
    "\n",
    "print(\"Corrélation = \",#ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c289ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a90f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e25a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12422ae0",
   "metadata": {},
   "source": [
    "> **Exercice 17:** À l'aide d'un QQplot. Observer si les lois de la production nucléaire est similaire lorsque la production solaire est supérieure ou inférieure à 1000TWh. Les échantillons étant de taille différente, on utilisera la fonction `np.interp`.\n",
    ">\n",
    "> Que peut-on conclure ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b52ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleaire_peu_solaire = puiss_2019.loc[#ToDo][#ToDo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "nucleaire_bcp_solaire = #ToDo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550711ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = nucleaire_peu_solaire.values\n",
    "test2 = nucleaire_bcp_solaire.values\n",
    "\n",
    "#Calcul des quantiles\n",
    "test1.sort()\n",
    "quantile_levels1 = #ToDo\n",
    "\n",
    "test2.sort()\n",
    "quantile_levels2 = #ToDo\n",
    "\n",
    "# the smaller set of quantile levels to create the plot\n",
    "quantile_levels = quantile_levels2\n",
    "\n",
    "#We already have the set of quantiles for the smaller data set\n",
    "quantiles2 = test2\n",
    "\n",
    "#We find the set of quantiles for the larger data set using linear interpolation\n",
    "quantiles1 = np.interp(quantile_levels,quantile_levels1,test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d352f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.plot(quantiles1,quantiles2, 'b', label = \"QQ plot\")\n",
    "plt.plot([25000,57000],[25000,57000], 'r', label = \"Droite\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel ('Solaire < 1000')\n",
    "plt.ylabel ('Solaire >= 1000')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f584b712",
   "metadata": {},
   "source": [
    "> **Exercice 18:** On considère la variable `Ensoleillement` qui vaut `Ensoleillé` lorsque `Solaire>=1000` et `Sombre` lorsque `Solaire<1000`.\n",
    ">\n",
    "> Faire un tableau représentant pour la première ligne les fréquences des moyens de production pour les journées `Ensoleillement = Ensoleillé` et la seconde ligne les fréquences des moyens de production pour les journées `Ensoleillement = Sombre`. Le comparer au tableau sous hypothèse d'indépendance.\n",
    ">\n",
    "> Effectuer un test du Chi2 d'indépendance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351f4cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5762be63",
   "metadata": {},
   "source": [
    "> **Question subsidiaire :** Faire une étude descriptive d'un autre jeu de données importé du site Eco2mix.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
